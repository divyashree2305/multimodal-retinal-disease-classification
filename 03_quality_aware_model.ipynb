{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AzYyJjZmiMj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os, cv2, random, glob, numpy as np, pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "BASE_DIR = '/../FIVES A Fundus Image Dataset for AI-based Vessel Segmentation'\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, 'train', 'Original')\n",
        "TEST_DIR  = os.path.join(BASE_DIR, 'test', 'Original')\n",
        "META_FILE = os.path.join(BASE_DIR, 'Quality Assessment.xlsx')\n",
        "\n",
        "RESULTS_DIR = '/../FIVES_results/quality_aware'\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 25\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h7BqI8uuhoH"
      },
      "outputs": [],
      "source": [
        "meta = pd.read_excel(META_FILE)\n",
        "print(\"Columns:\", list(meta.columns), \"Rows:\", len(meta))\n",
        "\n",
        "def find_image_path(disease, number):\n",
        "    fname = f\"{int(number)}_{disease}.png\"\n",
        "    for d in [TRAIN_DIR, TEST_DIR]:\n",
        "        p = os.path.join(d, fname)\n",
        "        if os.path.exists(p): return p\n",
        "    return None\n",
        "\n",
        "meta['filename'] = meta.apply(lambda r: f\"{int(r['Number'])}_{r['Disease']}.png\", axis=1)\n",
        "meta['image_path'] = meta.apply(lambda r: find_image_path(r['Disease'], r['Number']), axis=1)\n",
        "meta = meta.dropna(subset=['image_path']).reset_index(drop=True)\n",
        "\n",
        "import json, shutil\n",
        "\n",
        "SHARED_MAP_PATH = '/../FIVES_results/label_map.json'\n",
        "if not os.path.exists(SHARED_MAP_PATH):\n",
        "    raise FileNotFoundError(\"Shared label_map.json not found! Run the baseline notebook first.\")\n",
        "\n",
        "label_map = json.load(open(SHARED_MAP_PATH))\n",
        "meta['label'] = meta['Disease'].map(label_map)\n",
        "NUM_CLASSES = len(label_map)\n",
        "\n",
        "# Copy it to this model’s result folder for consistency\n",
        "shutil.copy(SHARED_MAP_PATH, os.path.join(RESULTS_DIR, 'label_map.json'))\n",
        "print(\"✅ Loaded shared label_map:\", label_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thxgzfoRukYu"
      },
      "outputs": [],
      "source": [
        "# === Load shared splits created by the baseline model ===\n",
        "SPLITS_DIR = '/../FIVES_results/splits'\n",
        "\n",
        "train_csv = os.path.join(SPLITS_DIR, 'train.csv')\n",
        "val_csv   = os.path.join(SPLITS_DIR, 'val.csv')\n",
        "test_csv  = os.path.join(SPLITS_DIR, 'test.csv')\n",
        "\n",
        "if not all(os.path.exists(p) for p in [train_csv, val_csv, test_csv]):\n",
        "    raise FileNotFoundError(\"❌ Train/val/test split files not found. Run baseline notebook first!\")\n",
        "\n",
        "train_df = pd.read_csv(train_csv)\n",
        "val_df   = pd.read_csv(val_csv)\n",
        "test_df  = pd.read_csv(test_csv)\n",
        "\n",
        "print(f\"✅ Loaded shared splits → Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FUjAkgeuoaz"
      },
      "outputs": [],
      "source": [
        "def preprocess_quality(img, ic, blur, lc):\n",
        "    \"\"\"Apply quality-based correction.\"\"\"\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "    # Illumination correction\n",
        "    if ic == 0:\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "        l,a,b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        l = clahe.apply(l)\n",
        "        img = cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2RGB)\n",
        "\n",
        "    # Deblur\n",
        "    if blur == 0:\n",
        "        img = cv2.GaussianBlur(img, (3,3), 0)\n",
        "        img = cv2.addWeighted(img, 1.5, img, -0.5, 0)\n",
        "\n",
        "    # Contrast enhancement\n",
        "    if lc == 0:\n",
        "        img = cv2.convertScaleAbs(img, alpha=1.2, beta=10)\n",
        "\n",
        "    return img\n",
        "\n",
        "def decode_preprocess(path, ic, blur, lc, label):\n",
        "    def _load_and_process(p, ic_val, bl_val, lc_val):\n",
        "        p = p.decode()\n",
        "        img = cv2.imread(p)\n",
        "        if img is None:\n",
        "            img = np.zeros((*IMG_SIZE, 3), np.uint8)\n",
        "        img = preprocess_quality(img, int(ic_val), int(bl_val), int(lc_val))\n",
        "        return img\n",
        "\n",
        "    img = tf.numpy_function(_load_and_process, [path, ic, blur, lc], tf.uint8)\n",
        "    img.set_shape([None, None, 3])\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "\n",
        "def make_dataset(df, training=True):\n",
        "    paths = df['image_path'].values\n",
        "    labels = df['label'].values\n",
        "    ic = df['IC'].values\n",
        "    bl = df['Blur'].values\n",
        "    lc = df['LC'].values\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, ic, bl, lc, labels))\n",
        "    ds = ds.map(decode_preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    if training:\n",
        "        ds = ds.shuffle(512, seed=SEED)\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = make_dataset(train_df)\n",
        "val_ds = make_dataset(val_df, False)\n",
        "test_ds = make_dataset(test_df, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gqxO5FWurMc"
      },
      "outputs": [],
      "source": [
        "base = tf.keras.applications.EfficientNetB0(include_top=False, pooling='avg', input_shape=IMG_SIZE+(3,))\n",
        "x = layers.Dropout(0.4)(base.output)\n",
        "out = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = models.Model(base.input, out)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3aWyFAjuxQ8"
      },
      "outputs": [],
      "source": [
        "ckpt = os.path.join(RESULTS_DIR, 'best_quality.keras')\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(ckpt, monitor='val_accuracy', save_best_only=True, mode='max'),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, mode='max', restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ62aFKpyLR1"
      },
      "outputs": [],
      "source": [
        "best_model = tf.keras.models.load_model(ckpt)\n",
        "y_true, y_pred, y_prob = [], [], []\n",
        "\n",
        "for imgs, labs in test_ds:\n",
        "    probs = best_model.predict(imgs, verbose=0)\n",
        "    preds = np.argmax(probs, axis=1)\n",
        "    y_true.extend(labs.numpy()); y_pred.extend(preds); y_prob.extend(probs)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=list(label_map.keys())))\n",
        "try:\n",
        "    auc = roc_auc_score(tf.keras.utils.to_categorical(y_true, NUM_CLASSES), np.array(y_prob), average='macro')\n",
        "    print(\"Macro AUC:\", round(auc,4))\n",
        "except: pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIb-ugqZUPYA"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.copy(SHARED_MAP_PATH, os.path.join(RESULTS_DIR, 'label_map.json'))\n",
        "print(\"Copied shared label_map to quality_aware results folder.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGtaOobEQtri"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jqj8feKTDIK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Paths\n",
        "RESULTS_DIR = '/../FIVES_results/quality_aware'\n",
        "MODEL_PATH = os.path.join(RESULTS_DIR, 'best_quality.keras')\n",
        "BASE_DIR = '/../FIVES A Fundus Image Dataset for AI-based Vessel Segmentation'\n",
        "TEST_DIR = os.path.join(BASE_DIR, 'test', 'Original')\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, 'train', 'Original')\n",
        "META_FILE = os.path.join(BASE_DIR, 'Quality Assessment.xlsx')\n",
        "\n",
        "# Load metadata\n",
        "meta = pd.read_excel(META_FILE)\n",
        "\n",
        "def find_image_path(disease, number):\n",
        "    fname = f\"{int(number)}_{disease}.png\"\n",
        "    for d in [TRAIN_DIR, TEST_DIR]:\n",
        "        p = os.path.join(d, fname)\n",
        "        if os.path.exists(p): return p\n",
        "    return None\n",
        "\n",
        "meta['image_path'] = meta.apply(lambda r: find_image_path(r['Disease'], r['Number']), axis=1)\n",
        "meta = meta.dropna(subset=['image_path']).reset_index(drop=True)\n",
        "\n",
        "# Load shared label map\n",
        "import json\n",
        "label_map_path = '/../FIVES_results/baseline/label_map.json'\n",
        "label_map = json.load(open(label_map_path))\n",
        "labels = list(label_map.keys())\n",
        "\n",
        "# Load trained model\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "print(\"✅ Loaded model:\", MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df6tA2kSTSSA"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 8\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def decode_resize(path, label):\n",
        "    img_bytes = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img_bytes, channels=3, expand_animations=False)\n",
        "    img.set_shape([None, None, 3])\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = tf.cast(img, tf.float32)/255.0\n",
        "    return img, label\n",
        "\n",
        "meta['label'] = meta['Disease'].map(label_map)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "_, temp_df = train_test_split(meta, test_size=0.2, stratify=meta['label'], random_state=42)\n",
        "_, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "paths = test_df['image_path'].values\n",
        "labels_np = test_df['label'].values\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((paths, labels_np))\n",
        "test_ds = test_ds.map(decode_resize, num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "print(f\"Test dataset ready ({len(test_df)} samples)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34jGOHEyQzbM"
      },
      "outputs": [],
      "source": [
        "y_true, y_pred, y_prob = [], [], []\n",
        "\n",
        "for imgs, labs in test_ds:\n",
        "    probs = best_model.predict(imgs, verbose=0)\n",
        "    preds = np.argmax(probs, axis=1)\n",
        "    y_true.extend(labs.numpy())\n",
        "    y_pred.extend(preds)\n",
        "    y_prob.extend(probs)\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_prob = np.array(y_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppiovK5gQ2az"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lCm4kEhQ-CC"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix – Quality-Aware Model\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0sjy89BRCEw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,6))\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "    fpr, tpr, _ = roc_curve(tf.keras.utils.to_categorical(y_true, len(labels))[:, i],\n",
        "                            y_prob[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, color=colors[i], lw=2,\n",
        "             label=f'{label} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves by Class – Quality-Aware Model')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbME13GXRFhn"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    macro_auc = roc_auc_score(tf.keras.utils.to_categorical(y_true, len(labels)),\n",
        "                              y_prob, average='macro')\n",
        "    print(\"Macro AUC:\", round(macro_auc, 4))\n",
        "except Exception as e:\n",
        "    print(\"AUC computation error:\", e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}