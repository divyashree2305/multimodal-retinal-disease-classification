{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8QAsha9Bvx6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"../FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "\n",
        "# Walk through all subfolders and count only PNGs\n",
        "counts = {}\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    png_count = len([f for f in files if f.lower().endswith(\".png\")])\n",
        "    if png_count > 0:\n",
        "        rel_path = os.path.relpath(root, dataset_path)  # relative path inside dataset\n",
        "        counts[rel_path] = png_count\n",
        "\n",
        "counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa87Kw57C44i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/data/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "\n",
        "train_orig = os.path.join(base_path, \"train/Original\")\n",
        "train_gt   = os.path.join(base_path, \"train/Ground truth\")\n",
        "\n",
        "orig_files = sorted([f for f in os.listdir(train_orig) if f.lower().endswith(\".png\")])\n",
        "gt_files   = sorted([f for f in os.listdir(train_gt) if f.lower().endswith(\".png\")])\n",
        "\n",
        "# Compare sets\n",
        "missing_in_gt = set(orig_files) - set(gt_files)\n",
        "extra_in_gt = set(gt_files) - set(orig_files)\n",
        "\n",
        "len(missing_in_gt), len(extra_in_gt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kosXd-LXDdP5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/data/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "\n",
        "train_orig = os.path.join(base_path, \"train/Original\")\n",
        "train_gt   = os.path.join(base_path, \"train/Ground truth\")\n",
        "\n",
        "# Collect only PNG filenames\n",
        "orig_files = sorted([f for f in os.listdir(train_orig) if f.lower().endswith(\".png\")])\n",
        "gt_files   = sorted([f for f in os.listdir(train_gt) if f.lower().endswith(\".png\")])\n",
        "\n",
        "# Find mismatches\n",
        "extra_in_gt = set(gt_files) - set(orig_files)\n",
        "\n",
        "# Show how many + some sample names\n",
        "print(\"Extra ground truth files:\", len(extra_in_gt))\n",
        "print(list(extra_in_gt)[:20])  # show first 20 for inspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9ITC5c0EMy2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/data/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "\n",
        "train_orig = os.path.join(base_path, \"train/Original\")\n",
        "train_gt   = os.path.join(base_path, \"train/Ground truth\")\n",
        "\n",
        "# Get only PNGs\n",
        "orig_files = set([f for f in os.listdir(train_orig) if f.lower().endswith(\".png\")])\n",
        "gt_files   = set([f for f in os.listdir(train_gt) if f.lower().endswith(\".png\")])\n",
        "\n",
        "# Find extra ground truth files\n",
        "extra_in_gt = gt_files - orig_files\n",
        "\n",
        "print(f\"Found {len(extra_in_gt)} redundant ground truth files.\")\n",
        "\n",
        "# Preview first 20 for confirmation\n",
        "print(\"Examples:\", list(extra_in_gt)[:20])\n",
        "\n",
        "# --- Remove redundant files ---\n",
        "for f in extra_in_gt:\n",
        "    os.remove(os.path.join(train_gt, f))\n",
        "\n",
        "print(\"✅ Redundant files removed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PCDUp3MEOYK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/data/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "\n",
        "def check_integrity(split):\n",
        "    orig_path = os.path.join(base_path, split, \"Original\")\n",
        "    gt_path   = os.path.join(base_path, split, \"Ground truth\")\n",
        "\n",
        "    orig_files = set([f for f in os.listdir(orig_path) if f.lower().endswith(\".png\")])\n",
        "    gt_files   = set([f for f in os.listdir(gt_path) if f.lower().endswith(\".png\")])\n",
        "\n",
        "    missing_in_gt = orig_files - gt_files\n",
        "    missing_in_orig = gt_files - orig_files\n",
        "\n",
        "    print(f\"--- {split.upper()} ---\")\n",
        "    print(f\"Original count: {len(orig_files)}\")\n",
        "    print(f\"Ground Truth count: {len(gt_files)}\")\n",
        "    print(f\"Missing in GT: {len(missing_in_gt)}\")\n",
        "    print(f\"Missing in Original: {len(missing_in_orig)}\")\n",
        "\n",
        "    # Show some sample mismatches if any\n",
        "    if missing_in_gt:\n",
        "        print(\"Examples missing in GT:\", list(missing_in_gt)[:5])\n",
        "    if missing_in_orig:\n",
        "        print(\"Examples missing in Original:\", list(missing_in_orig)[:5])\n",
        "    print()\n",
        "\n",
        "# Run checks for both\n",
        "check_integrity(\"train\")\n",
        "check_integrity(\"test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKh6bZsiq5-Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Paths (update if needed)\n",
        "base_path = \"/data/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "train_gt = os.path.join(base_path, \"train/Ground truth\")\n",
        "test_gt = os.path.join(base_path, \"test/Ground truth\")\n",
        "excel_path = os.path.join(base_path, \"Quality Assessment.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jizo_nntrIR6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"Base path exists:\", os.path.exists(base_path))\n",
        "print(\"Train GT path exists:\", os.path.exists(train_gt))\n",
        "print(\"Test GT path exists:\", os.path.exists(test_gt))\n",
        "print(\"Excel file exists:\", os.path.exists(excel_path))\n",
        "print(\"\\nSample Train GT files:\", os.listdir(train_gt)[:5])\n",
        "print(\"Sample Test GT files:\", os.listdir(test_gt)[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7u8jsk2rlPw"
      },
      "outputs": [],
      "source": [
        "# Load both sheets from Excel\n",
        "df_train = pd.read_excel(excel_path, sheet_name=\"Train\")\n",
        "df_test  = pd.read_excel(excel_path, sheet_name=\"Test\")\n",
        "\n",
        "# Map disease to numeric labels\n",
        "label_map = {\"A\":0, \"D\":1, \"G\":2, \"N\":3}\n",
        "df_train[\"label\"] = df_train[\"Disease\"].map(label_map)\n",
        "df_test[\"label\"]  = df_test[\"Disease\"].map(label_map)\n",
        "\n",
        "print(\"Train sheet sample:\")\n",
        "print(df_train.head())\n",
        "\n",
        "print(\"\\nTest sheet sample:\")\n",
        "print(df_test.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OdmVjhxtKbl"
      },
      "outputs": [],
      "source": [
        "class FundusMaskDataset(Dataset):\n",
        "    def __init__(self, img_dir, df, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "\n",
        "        for fname in os.listdir(img_dir):\n",
        "            if fname.endswith(\".png\"):\n",
        "                # Format: Number_Disease.png (e.g., 1_A.png)\n",
        "                number = int(fname.split(\"_\")[0])\n",
        "                disease = fname.split(\"_\")[1].split(\".\")[0]\n",
        "\n",
        "                # Match with sheet data\n",
        "                row = df[(df[\"Disease\"] == disease) & (df[\"Number\"] == number)]\n",
        "                if not row.empty:\n",
        "                    label = int(row[\"label\"].values[0])\n",
        "                    self.samples.append((fname, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname, label = self.samples[idx]\n",
        "        img_path = os.path.join(self.img_dir, fname)\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfyQXEbbtPWr"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = FundusMaskDataset(train_gt, df_train, transform=transform)\n",
        "test_dataset  = FundusMaskDataset(test_gt, df_test, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Test samples:\", len(test_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwxNL4F7tS5f"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 4)  # 4 classes (A, D, G, N)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWkDAfabtYpQ"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "    acc = correct / len(loader.dataset)\n",
        "    return total_loss/len(loader), acc\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "    acc = correct / len(loader.dataset)\n",
        "    return total_loss/len(loader), acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WBSJSGyKtcww"
      },
      "outputs": [],
      "source": [
        "for epoch in range(5):  # run a few epochs first\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "    print(f\"Epoch {epoch+1}: Train Acc={train_acc:.2f}, Test Acc={test_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Po8ar7oZzM9V"
      },
      "outputs": [],
      "source": [
        "save_path = \"/../fundus_baseline_resnet18.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(\"Model saved at:\", save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SVa0qjMFzOvX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def show_predictions(model, loader, n=6):\n",
        "    model.eval()\n",
        "    imgs, labels = next(iter(loader))\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(imgs)\n",
        "        preds = outputs.argmax(1)\n",
        "\n",
        "    imgs = imgs.cpu().numpy().transpose(0,2,3,1)\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for i in range(n):\n",
        "        plt.subplot(2, n//2, i+1)\n",
        "        plt.imshow(imgs[i])\n",
        "        plt.axis(\"off\")\n",
        "        true_lbl = list(label_map.keys())[list(label_map.values()).index(labels[i].item())]\n",
        "        pred_lbl = list(label_map.keys())[list(label_map.values()).index(preds[i].item())]\n",
        "        plt.title(f\"T:{true_lbl}, P:{pred_lbl}\")\n",
        "    plt.show()\n",
        "\n",
        "# Show predictions\n",
        "show_predictions(model, test_loader, n=6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hyFWdFltzlpL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "\n",
        "def plot_confusion_matrix(model, loader, classes):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            preds = outputs.argmax(1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(len(classes))))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "    disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Define class names (match Excel mapping)\n",
        "class_names = [\"A (AMD)\", \"D (DR)\", \"G (Glaucoma)\", \"N (Normal)\"]\n",
        "\n",
        "plot_confusion_matrix(model, test_loader, class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NZ5WyZESG5mR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Paths (update if needed)\n",
        "base_path = \"/../FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "train_original = os.path.join(base_path, \"train/Original\")\n",
        "train_segmented = os.path.join(base_path, \"train/Ground truth\")\n",
        "test_original = os.path.join(base_path, \"test/Original\")\n",
        "test_segmented = os.path.join(base_path, \"test/Ground truth\")\n",
        "excel_path = os.path.join(base_path, \"Quality Assessment.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VPjmRQXVG-Z6"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_excel(excel_path, sheet_name=\"Train\")\n",
        "df_test  = pd.read_excel(excel_path, sheet_name=\"Test\")\n",
        "\n",
        "print(\"Train Sheet:\\n\", df_train.head())\n",
        "print(\"\\nTest Sheet:\\n\", df_test.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iTsfOAAwHD4E"
      },
      "outputs": [],
      "source": [
        "label_map = {\"A\": \"AMD\", \"D\": \"DR\", \"G\": \"Glaucoma\", \"N\": \"Normal\"}\n",
        "\n",
        "df_train[\"DiseaseName\"] = df_train[\"Disease\"].map(label_map)\n",
        "df_test[\"DiseaseName\"] = df_test[\"Disease\"].map(label_map)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
        "\n",
        "sns.countplot(data=df_train, x=\"DiseaseName\", ax=axes[0], palette=\"viridis\")\n",
        "axes[0].set_title(\"Train Set Disease Distribution\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "axes[0].set_xlabel(\"Disease\")\n",
        "\n",
        "sns.countplot(data=df_test, x=\"DiseaseName\", ax=axes[1], palette=\"magma\")\n",
        "axes[1].set_title(\"Test Set Disease Distribution\")\n",
        "axes[1].set_ylabel(\"Count\")\n",
        "axes[1].set_xlabel(\"Disease\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kztvo52mHJ5C"
      },
      "outputs": [],
      "source": [
        "def count_pngs(path):\n",
        "    return len([f for f in os.listdir(path) if f.endswith(\".png\")])\n",
        "\n",
        "counts = {\n",
        "    \"Train Original\": count_pngs(train_original),\n",
        "    \"Train Segmented\": count_pngs(train_segmented),\n",
        "    \"Test Original\": count_pngs(test_original),\n",
        "    \"Test Segmented\": count_pngs(test_segmented)\n",
        "}\n",
        "\n",
        "print(\"Image counts per folder:\")\n",
        "for k,v in counts.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GPqbFpfGHO9g"
      },
      "outputs": [],
      "source": [
        "def show_random_pairs(n=4):\n",
        "    files = random.sample(os.listdir(train_original), n)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i, fname in enumerate(files):\n",
        "        # Paths\n",
        "        orig_path = os.path.join(train_original, fname)\n",
        "        seg_path = os.path.join(train_segmented, fname)\n",
        "\n",
        "        # Open images\n",
        "        orig = Image.open(orig_path).convert(\"RGB\")\n",
        "        seg = Image.open(seg_path).convert(\"L\")\n",
        "\n",
        "        # Plot original\n",
        "        plt.subplot(2, n, i+1)\n",
        "        plt.imshow(orig)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"Original: {fname}\")\n",
        "\n",
        "        # Plot segmented\n",
        "        plt.subplot(2, n, n+i+1)\n",
        "        plt.imshow(seg, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"Segmented\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_random_pairs(n=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G8MRRvDaHYF4"
      },
      "outputs": [],
      "source": [
        "sizes = []\n",
        "for fname in os.listdir(train_original):\n",
        "    if fname.endswith(\".png\"):\n",
        "        img = Image.open(os.path.join(train_original, fname))\n",
        "        sizes.append(img.size)\n",
        "\n",
        "df_sizes = pd.DataFrame(sizes, columns=[\"Width\", \"Height\"])\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df_sizes[\"Width\"], bins=20, kde=True, color=\"blue\", label=\"Width\")\n",
        "sns.histplot(df_sizes[\"Height\"], bins=20, kde=True, color=\"orange\", label=\"Height\")\n",
        "plt.legend()\n",
        "plt.title(\"Image Size Distribution (Train Original)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjZaDt2KKajd"
      },
      "source": [
        "# CLASSIFICATION USING RAW FUNDUS IMAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0QOS_UaKICJV"
      },
      "outputs": [],
      "source": [
        "# Core\n",
        "import os, re, random, numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Torch / Vision\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ---- PATHS: update base_path if needed ----\n",
        "base_path = \"/data/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "train_original = os.path.join(base_path, \"train/Original\")\n",
        "test_original  = os.path.join(base_path, \"test/Original\")\n",
        "excel_path     = os.path.join(base_path, \"Quality Assessment.xlsx\")\n",
        "\n",
        "print(\"Base exists:\", os.path.exists(base_path))\n",
        "print(\"Train Original exists:\", os.path.exists(train_original))\n",
        "print(\"Test Original exists:\", os.path.exists(test_original))\n",
        "print(\"Excel exists:\", os.path.exists(excel_path))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_Ajvr8rEKotY"
      },
      "outputs": [],
      "source": [
        "# Sheets named exactly \"Train\" and \"Test\"\n",
        "df_train = pd.read_excel(excel_path, sheet_name=\"Train\")\n",
        "df_test  = pd.read_excel(excel_path, sheet_name=\"Test\")\n",
        "\n",
        "# Map disease codes to integers\n",
        "label_map = {\"A\":0, \"D\":1, \"G\":2, \"N\":3}\n",
        "inv_label_map = {v:k for k,v in label_map.items()}\n",
        "\n",
        "df_train[\"Disease\"] = df_train[\"Disease\"].astype(str).str.upper()\n",
        "df_test[\"Disease\"]  = df_test[\"Disease\"].astype(str).str.upper()\n",
        "df_train[\"label\"] = df_train[\"Disease\"].map(label_map)\n",
        "df_test[\"label\"]  = df_test[\"Disease\"].map(label_map)\n",
        "\n",
        "print(\"Train sheet sample:\\n\", df_train.head(3))\n",
        "print(\"\\nTest sheet sample:\\n\", df_test.head(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YRYWcPyVKvKR"
      },
      "outputs": [],
      "source": [
        "class FundusOriginalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Loads ORIGINAL RGB images for classification.\n",
        "    Expects filenames like:  1_A.png, 23_D.png, etc.\n",
        "    Matches (Number, Disease) to Excel row to get label.\n",
        "    \"\"\"\n",
        "    def __init__(self, img_dir, df, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.df = df.copy()\n",
        "        self.transform = transform\n",
        "        self.samples = []   # list of (fname, label)\n",
        "\n",
        "        pattern = re.compile(r\"^\\s*(\\d+)_([ADGNadgn])\\.(png|PNG)$\")\n",
        "        files = [f for f in os.listdir(img_dir) if f.lower().endswith(\".png\")]\n",
        "\n",
        "        for fname in files:\n",
        "            m = pattern.match(fname)\n",
        "            if not m:\n",
        "                continue\n",
        "            number = int(m.group(1))\n",
        "            disease = m.group(2).upper()\n",
        "\n",
        "            row = self.df[(self.df[\"Number\"] == number) & (self.df[\"Disease\"] == disease)]\n",
        "            if not row.empty:\n",
        "                label = int(row[\"label\"].values[0])\n",
        "                self.samples.append((fname, label))\n",
        "\n",
        "        # Basic sanity\n",
        "        if len(self.samples) == 0:\n",
        "            print(f\"[WARN] No samples matched in {img_dir}. Check naming and Excel mapping.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname, label = self.samples[idx]\n",
        "        path = os.path.join(self.img_dir, fname)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label, fname\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zgZ6Hu26Kyqa"
      },
      "outputs": [],
      "source": [
        "# ImageNet normalization for pretrained backbones\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "train_ds = FundusOriginalDataset(train_original, df_train, transform=train_tfms)\n",
        "test_ds  = FundusOriginalDataset(test_original,  df_test,  transform=test_tfms)\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Train samples:\", len(train_ds))\n",
        "print(\"Test samples:\", len(test_ds))\n",
        "\n",
        "# Peek a few mappings\n",
        "for i in range(min(5, len(train_ds))):\n",
        "    _, lbl, fname = train_ds[i]\n",
        "    print(f\"Example -> {fname}  => label {lbl} ({inv_label_map[lbl]})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY_NEFvIK7v6"
      },
      "outputs": [],
      "source": [
        "# Compute class weights from the *actual loaded* training samples (handles missing files)\n",
        "labels_in_train = [lbl for _, lbl in train_ds.samples]\n",
        "class_counts = np.bincount(labels_in_train, minlength=4)\n",
        "class_weights = (len(labels_in_train) / (4.0 * np.maximum(class_counts, 1))).astype(np.float32)\n",
        "print(\"Class counts:\", class_counts)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "weights_tensor = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
        "\n",
        "# Model\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, 4)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbIyUPn0MXQJ"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    pbar = tqdm(loader, desc=f\"Epoch {epoch} [train]\", leave=False)\n",
        "    for imgs, labels, _ in pbar:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        preds = out.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        pbar.set_postfix(loss=running_loss/total, acc=correct/total)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for imgs, labels, _ in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        preds = out.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return running_loss/total, correct/total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiudYYrrMdpk"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "for ep in range(1, epochs+1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, ep)\n",
        "    te_loss, te_acc = evaluate(model, test_loader, criterion)\n",
        "    print(f\"Epoch {ep:02d} | train: loss {tr_loss:.4f}, acc {tr_acc:.3f} | test: loss {te_loss:.4f}, acc {te_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM0x68HRPRT7"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def preds_and_labels(model, loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    for imgs, labels, _ in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        out = model(imgs)\n",
        "        all_preds.extend(out.argmax(1).cpu().numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "preds, gts = preds_and_labels(model, test_loader)\n",
        "cm = confusion_matrix(gts, preds, labels=[0,1,2,3])\n",
        "print(\"Confusion Matrix (rows=true A,D,G,N; cols=pred A,D,G,N):\\n\", cm)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"A\",\"D\",\"G\",\"N\"])\n",
        "disp.plot(values_format=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Original-only Baseline — Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFcMB-DTfcLc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# 1️⃣ Accuracy\n",
        "acc = accuracy_score(gts, preds)\n",
        "print(\"Accuracy:\", acc)\n",
        "\n",
        "# 2️⃣ Precision, Recall, F1-score (macro/micro/weighted)\n",
        "# Macro: unweighted mean per class\n",
        "# Micro: global metrics by counting all TP, FP, FN\n",
        "# Weighted: mean per class weighted by support\n",
        "precision = precision_score(gts, preds, average='macro')\n",
        "recall = recall_score(gts, preds, average='macro')\n",
        "f1 = f1_score(gts, preds, average='macro')\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
        "\n",
        "# 3️⃣ Per-class metrics\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(gts, preds, target_names=[\"A\",\"D\",\"G\",\"N\"]))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}