{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD0kNVfopsEk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# quick path check\n",
        "import os\n",
        "base_path = \"/../FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "print(os.listdir(base_path))   # should show train, test, Quality Assessment.xlsx (or similar)\n",
        "\n",
        "# load metadata\n",
        "import pandas as pd\n",
        "excel_path = os.path.join(base_path, \"Quality Assessment.xlsx\")\n",
        "df = pd.read_excel(excel_path)\n",
        "df.head(), df.shape, df.columns.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "excel_path = \"/../FIVES A Fundus Image Dataset for AI-based Vessel Segmentation/Quality Assessment.xlsx\"\n",
        "\n",
        "df_train = pd.read_excel(excel_path, sheet_name=\"Train\")\n",
        "df_test = pd.read_excel(excel_path, sheet_name=\"Test\")\n",
        "\n",
        "df_train.head(), df_test.head()\n"
      ],
      "metadata": {
        "id": "xwVEWckHt8gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/../FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "train_img_dir = os.path.join(base_path, \"train\", \"Original\")\n",
        "test_img_dir = os.path.join(base_path, \"test\", \"Original\")\n"
      ],
      "metadata": {
        "id": "WbySlicmt9h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"filename\"] = df_train[\"Number\"].astype(str) + \"_\" + df_train[\"Disease\"].astype(str) + \".png\"\n",
        "df_test[\"filename\"] = df_test[\"Number\"].astype(str) + \"_\" + df_test[\"Disease\"].astype(str) + \".png\"\n"
      ],
      "metadata": {
        "id": "YVK0VBMHuATl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"image_path\"] = df_train[\"filename\"].apply(lambda x: os.path.join(train_img_dir, x))\n",
        "df_test[\"image_path\"] = df_test[\"filename\"].apply(lambda x: os.path.join(test_img_dir, x))\n"
      ],
      "metadata": {
        "id": "VT6K0VY4uC86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_train = [f for f in df_train[\"image_path\"] if not os.path.exists(f)]\n",
        "missing_test = [f for f in df_test[\"image_path\"] if not os.path.exists(f)]\n",
        "\n",
        "print(\"Missing in train:\", len(missing_train))\n",
        "print(\"Missing in test:\", len(missing_test))\n"
      ],
      "metadata": {
        "id": "-k-v6OxHuFg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mapped = df_train[[\"image_path\", \"IC\", \"Blur\", \"LC\", \"Disease\"]]\n",
        "test_mapped = df_test[[\"image_path\", \"IC\", \"Blur\", \"LC\", \"Disease\"]]\n"
      ],
      "metadata": {
        "id": "jKaO9NIkuIbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mapped.to_csv(\"/../train_mapped.csv\", index=False)\n",
        "test_mapped.to_csv(\"/../test_mapped.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZBOFtAFSlk_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train samples:\", len(train_mapped))\n",
        "print(\"Test samples:\", len(test_mapped))"
      ],
      "metadata": {
        "id": "QzZDnnMWtc9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "izhqoyKOtesc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_mapped[\"Disease\"].unique())"
      ],
      "metadata": {
        "id": "ISAfDEwwtlCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\"A\": 0, \"D\": 1, \"G\": 2, \"N\": 3}\n",
        "train_mapped[\"label\"] = train_mapped[\"Disease\"].map(label_map)\n",
        "test_mapped[\"label\"] = test_mapped[\"Disease\"].map(label_map)"
      ],
      "metadata": {
        "id": "Y-VrnyjVuEYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),     # or (256, 256) depending on backbone\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "Hcr4YOHbuZ_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class RetinaDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # Load image\n",
        "        img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Metadata as tensor\n",
        "        metadata = torch.tensor(\n",
        "            [row[\"IC\"], row[\"Blur\"], row[\"LC\"]],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # Label\n",
        "        label = torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "\n",
        "        return img, metadata, label"
      ],
      "metadata": {
        "id": "XHf_X92vvBUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = RetinaDataset(train_mapped, transform=image_transforms)\n",
        "test_dataset = RetinaDataset(test_mapped, transform=image_transforms)"
      ],
      "metadata": {
        "id": "1meYDTi0vGb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "n2_NR4nbvLh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, metadata, labels = next(iter(train_loader))\n",
        "print(\"Image batch shape:\", images.shape)      # Expect: [batch, 3, H, W]\n",
        "print(\"Metadata batch shape:\", metadata.shape) # Expect: [batch, 3]\n",
        "print(\"Labels shape:\", labels.shape)           # Expect: [batch]"
      ],
      "metadata": {
        "id": "_m4-hHK4vRC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class MultimodalModel(nn.Module):\n",
        "    def __init__(self, metadata_input_dim, num_classes):\n",
        "        super(MultimodalModel, self).__init__()\n",
        "\n",
        "        # Image feature extractor (CNN backbone)\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        self.cnn.fc = nn.Identity()  # Remove final layer to get embeddings\n",
        "\n",
        "        # Metadata MLP\n",
        "        self.metadata_fc = nn.Sequential(\n",
        "            nn.Linear(metadata_input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Combined classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 + 8, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, images, metadata):\n",
        "        img_features = self.cnn(images)\n",
        "        meta_features = self.metadata_fc(metadata)\n",
        "        combined = torch.cat((img_features, meta_features), dim=1)\n",
        "        out = self.classifier(combined)\n",
        "        return out"
      ],
      "metadata": {
        "id": "KqMt4rSOv0PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_input_dim = 3  # since your metadata batch is [16, 3]\n",
        "num_classes = 4  # change if different\n",
        "\n",
        "model = MultimodalModel(metadata_input_dim, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "5g48n9_Vv2-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "XTZTS6iIv6-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "num_epochs = 5  # you can increase later\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, metadata, labels in train_loader:\n",
        "        # Add this print statement\n",
        "        print(\"Labels before moving to device:\", labels)\n",
        "        # Move to GPU if available\n",
        "        images = images.to(device)\n",
        "        metadata = metadata.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, metadata)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "lq36QIAuw1T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "torch.save(model.state_dict(), \"/../multimodal_model.pth\")"
      ],
      "metadata": {
        "id": "0ahlavUl7fhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "yyQlDvd27k0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultimodalModel(nn.Module):\n",
        "    def __init__(self, metadata_input_dim, num_classes):\n",
        "        super(MultimodalModel, self).__init__()\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        self.cnn.fc = nn.Identity()  # remove final layer\n",
        "\n",
        "        self.metadata_fc = nn.Sequential(\n",
        "            nn.Linear(metadata_input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 + 8, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, images, metadata):\n",
        "        img_features = self.cnn(images)\n",
        "        meta_features = self.metadata_fc(metadata)\n",
        "        combined = torch.cat((img_features, meta_features), dim=1)\n",
        "        return self.classifier(combined)\n"
      ],
      "metadata": {
        "id": "oLL98KS3l9Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_input_dim = 3\n",
        "num_classes = 4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MultimodalModel(metadata_input_dim, num_classes).to(device)"
      ],
      "metadata": {
        "id": "3_bUsMWXl-ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/../multimodal_model.pth\", map_location=device))\n",
        "model.eval()  # important for inference"
      ],
      "metadata": {
        "id": "g3jixntamC45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_mapped = pd.read_csv(\"/../test_mapped.csv\")"
      ],
      "metadata": {
        "id": "VfYKpy9lmP7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class FundusDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        metadata = torch.tensor([row[\"IC\"], row[\"Blur\"], row[\"LC\"]], dtype=torch.float32)\n",
        "        label = torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "        return image, metadata, label"
      ],
      "metadata": {
        "id": "62qsCG1zoF4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_dataset = FundusDataset(test_mapped, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "uRE8GxLGoHpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the 'label' column back to test_mapped\n",
        "label_map = {\"A\": 0, \"D\": 1, \"G\": 2, \"N\": 3}\n",
        "test_mapped[\"label\"] = test_mapped[\"Disease\"].map(label_map)\n",
        "\n",
        "images, metadata, labels = next(iter(test_loader))\n",
        "images, metadata = images.to(device), metadata.to(device)\n",
        "outputs = model(images, metadata)\n",
        "_, predicted = torch.max(outputs, 1)"
      ],
      "metadata": {
        "id": "N70O9EiemV6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_outputs = [] # List to store model outputs (logits)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, metadata, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        metadata = metadata.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images, metadata)\n",
        "\n",
        "        all_outputs.append(outputs.cpu().numpy()) # Store outputs\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Concatenate all outputs\n",
        "all_outputs_np = np.concatenate(all_outputs, axis=0)\n",
        "all_probs = torch.nn.functional.softmax(torch.tensor(all_outputs_np), dim=1).numpy() # Calculate probabilities\n",
        "\n",
        "# ðŸ“Š Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=['A', 'D', 'G', 'N']))\n",
        "\n",
        "# ðŸ“ˆ Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(all_labels, all_preds))\n",
        "\n",
        "# --- ROC Curves ---\n",
        "y_true_bin = label_binarize(all_labels, classes=[0, 1, 2, 3])\n",
        "n_classes = y_true_bin.shape[1]\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], all_probs[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f\"Class {i} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "plt.title(\"ROC Curves by Class\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V25mSJPIoidO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, roc_curve, auc,\n",
        "    roc_auc_score, precision_recall_curve,\n",
        "    classification_report\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Assuming you already have:\n",
        "# all_labels (actual labels), all_preds (predicted labels) from the previous cell\n",
        "\n",
        "# Convert logits to probabilities (need to re-run the test set evaluation to get outputs)\n",
        "# For now, we will use the outputs from the last batch, but for full evaluation,\n",
        "# you would need to collect all outputs during the test loop.\n",
        "# Let's assume 'outputs' from the last batch is available for demonstration of plotting.\n",
        "# If you need plots for the entire test set, you'll need to collect all outputs during evaluation.\n",
        "\n",
        "# Since we don't have all outputs, we'll skip ROC and Precision-Recall for now and just plot the confusion matrix.\n",
        "# To plot ROC and PR for the entire test set, you would need to modify the evaluation loop in the previous cell\n",
        "# to store all outputs (logits) in a list, similar to how all_preds and all_labels are collected.\n",
        "\n",
        "# --- CONFUSION MATRIX ---\n",
        "plt.figure(figsize=(6, 5))\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"A\", \"D\", \"G\", \"N\"],\n",
        "            yticklabels=[\"A\", \"D\", \"G\", \"N\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# --- ROC CURVES ---\n",
        "# To plot ROC curves for the entire test set, you would need to collect all model outputs (logits)\n",
        "# during the evaluation loop in the previous cell and then calculate probabilities from them.\n",
        "# Example (if you had all_outputs list):\n",
        "# all_outputs_tensor = torch.cat(all_outputs, dim=0)\n",
        "# all_probs = torch.nn.functional.softmax(all_outputs_tensor, dim=1).cpu().detach().numpy()\n",
        "# y_true_bin = label_binarize(all_labels, classes=[0, 1, 2, 3])\n",
        "# n_classes = y_true_bin.shape[1]\n",
        "\n",
        "# plt.figure(figsize=(7, 6))\n",
        "# for i in range(n_classes):\n",
        "#     fpr, tpr, _ = roc_curve(y_true_bin[:, i], all_probs[:, i])\n",
        "#     roc_auc = auc(fpr, tpr)\n",
        "#     plt.plot(fpr, tpr, lw=2, label=f\"Class {i} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "# plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "# plt.title(\"ROC Curves by Class\")\n",
        "# plt.xlabel(\"False Positive Rate\")\n",
        "# plt.ylabel(\"True Positive Rate\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# --- PRECISION-RECALL CURVES ---\n",
        "# Similar to ROC curves, you would need all_probs for this.\n",
        "# plt.figure(figsize=(7, 6))\n",
        "# for i in range(n_classes):\n",
        "#     precision, recall, _ = precision_recall_curve(y_true_bin[:, i], all_probs[:, i])\n",
        "#     plt.plot(recall, precision, lw=2, label=f\"Class {i}\")\n",
        "\n",
        "# plt.title(\"Precision-Recall Curves\")\n",
        "# plt.xlabel(\"Recall\")\n",
        "# plt.ylabel(\"Precision\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# --- AUC Summary ---\n",
        "# Need all_probs for this.\n",
        "# auc_macro = roc_auc_score(y_true_bin, all_probs, average='macro')\n",
        "# auc_weighted = roc_auc_score(y_true_bin, all_probs, average='weighted')\n",
        "# print(f\"Macro AUC: {auc_macro:.3f}, Weighted AUC: {auc_weighted:.3f}\")"
      ],
      "metadata": {
        "id": "HHV3Ft2prj0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}