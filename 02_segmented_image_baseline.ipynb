{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5NIl-Ur9Ipt"
      },
      "outputs": [],
      "source": [
        "# Core\n",
        "import os, re, random, numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Torch / Vision\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models, datasets\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ---- PATHS: update base_path if needed ----\n",
        "base_path = \"/../FIVES A Fundus Image Dataset for AI-based Vessel Segmentation\"\n",
        "train_gt = os.path.join(base_path, \"train/Ground truth\")\n",
        "test_gt  = os.path.join(base_path, \"test/Ground truth\")\n",
        "excel_path = os.path.join(base_path, \"Quality Assessment.xlsx\")\n",
        "\n",
        "print(\"Base exists:\", os.path.exists(base_path))\n",
        "print(\"Train Ground Truth exists:\", os.path.exists(train_gt))\n",
        "print(\"Test Ground Truth exists:\", os.path.exists(test_gt))\n",
        "print(\"Excel exists:\", os.path.exists(excel_path))\n",
        "\n",
        "# ---- Device ----\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sheets named exactly \"Train\" and \"Test\"\n",
        "df_train = pd.read_excel(excel_path, sheet_name=\"Train\")\n",
        "df_test  = pd.read_excel(excel_path, sheet_name=\"Test\")\n",
        "\n",
        "# Map disease codes to integers\n",
        "label_map = {\"A\":0, \"D\":1, \"G\":2, \"N\":3}\n",
        "inv_label_map = {v:k for k,v in label_map.items()}\n",
        "\n",
        "df_train[\"Disease\"] = df_train[\"Disease\"].astype(str).str.upper()\n",
        "df_test[\"Disease\"]  = df_test[\"Disease\"].astype(str).str.upper()\n",
        "df_train[\"label\"] = df_train[\"Disease\"].map(label_map)\n",
        "df_test[\"label\"]  = df_test[\"Disease\"].map(label_map)\n",
        "\n",
        "print(\"Train sheet sample:\\n\", df_train.head(3))\n",
        "print(\"\\nTest sheet sample:\\n\", df_test.head(3))\n"
      ],
      "metadata": {
        "id": "VKfARTB_9Rpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FundusGTDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Loads GROUND TRUTH (segmented) images for classification.\n",
        "    Expects filenames like:  1_A.png, 23_D.png, etc.\n",
        "    Matches (Number, Disease) to Excel row to get label.\n",
        "    \"\"\"\n",
        "    def __init__(self, img_dir, df, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.df = df.copy()\n",
        "        self.transform = transform\n",
        "        self.samples = []   # list of (fname, label)\n",
        "\n",
        "        pattern = re.compile(r\"^\\s*(\\d+)_([ADGNadgn])\\.(png|PNG)$\")\n",
        "        files = [f for f in os.listdir(img_dir) if f.lower().endswith(\".png\")]\n",
        "\n",
        "        for fname in files:\n",
        "            m = pattern.match(fname)\n",
        "            if not m:\n",
        "                continue\n",
        "            number = int(m.group(1))\n",
        "            disease = m.group(2).upper()\n",
        "\n",
        "            row = self.df[(self.df[\"Number\"] == number) & (self.df[\"Disease\"] == disease)]\n",
        "            if not row.empty:\n",
        "                label = int(row[\"label\"].values[0])\n",
        "                self.samples.append((fname, label))\n",
        "\n",
        "        # Basic sanity\n",
        "        if len(self.samples) == 0:\n",
        "            print(f\"[WARN] No samples matched in {img_dir}. Check naming and Excel mapping.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname, label = self.samples[idx]\n",
        "        path = os.path.join(self.img_dir, fname)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label, fname\n"
      ],
      "metadata": {
        "id": "ztbG6kcT9Sr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageNet normalization for pretrained backbones\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "# ---- Ground Truth datasets ----\n",
        "train_ds = FundusGTDataset(train_gt, df_train, transform=train_tfms)\n",
        "test_ds  = FundusGTDataset(test_gt,  df_test,  transform=test_tfms)\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Train samples:\", len(train_ds))\n",
        "print(\"Test samples:\", len(test_ds))\n",
        "\n",
        "# Peek a few mappings\n",
        "for i in range(min(5, len(train_ds))):\n",
        "    _, lbl, fname = train_ds[i]\n",
        "    print(f\"Example -> {fname}  => label {lbl} ({inv_label_map[lbl]})\")\n"
      ],
      "metadata": {
        "id": "_cTHwpMG9quu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights from the actual loaded Ground Truth training samples\n",
        "labels_in_train = [lbl for _, lbl in train_ds.samples]\n",
        "class_counts = np.bincount(labels_in_train, minlength=4)\n",
        "class_weights = (len(labels_in_train) / (4.0 * np.maximum(class_counts, 1))).astype(np.float32)\n",
        "print(\"Class counts:\", class_counts)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "weights_tensor = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
        "\n",
        "# Model\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, 4)  # 4 classes: A,D,G,N\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "SvDIKcBt91kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    pbar = tqdm(loader, desc=f\"Epoch {epoch} [train]\", leave=False)\n",
        "    for imgs, labels, _ in pbar:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        preds = out.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        pbar.set_postfix(loss=running_loss/total, acc=correct/total)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for imgs, labels, _ in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        preds = out.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return running_loss/total, correct/total\n"
      ],
      "metadata": {
        "id": "VBbzrHvw-FRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for ep in range(1, epochs+1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, ep)\n",
        "    te_loss, te_acc = evaluate(model, test_loader, criterion)\n",
        "    print(f\"Epoch {ep:02d} | train: loss {tr_loss:.4f}, acc {tr_acc:.3f} | test: loss {te_loss:.4f}, acc {te_acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "nSBB0vB5-dDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def preds_and_labels(model, loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    for imgs, labels, _ in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        out = model(imgs)\n",
        "        all_preds.extend(out.argmax(1).cpu().numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "preds, gts = preds_and_labels(model, test_loader)\n",
        "cm = confusion_matrix(gts, preds, labels=[0,1,2,3])\n",
        "print(\"Confusion Matrix (rows=true A,D,G,N; cols=pred A,D,G,N):\\n\", cm)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"A\",\"D\",\"G\",\"N\"])\n",
        "disp.plot(values_format=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Original-only Baseline — Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sJqFCVqB_FG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# 1️⃣ Accuracy\n",
        "acc = accuracy_score(gts, preds)\n",
        "print(\"Accuracy:\", acc)\n",
        "\n",
        "# 2️⃣ Precision, Recall, F1-score (macro/micro/weighted)\n",
        "precision = precision_score(gts, preds, average='macro')\n",
        "recall = recall_score(gts, preds, average='macro')\n",
        "f1 = f1_score(gts, preds, average='macro')\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "# 3️⃣ Per-class metrics\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(gts, preds, target_names=[\"A\",\"D\",\"G\",\"N\"]))\n"
      ],
      "metadata": {
        "id": "Owx-KoSf_GeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/../segmented_trained_weights.pth\"\n",
        "\n",
        "# Save the model's state_dict\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(\"Segmented-trained model weights saved to:\", save_path)"
      ],
      "metadata": {
        "id": "6kGnOZx8eezM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Denormalize for display\n",
        "def denorm(img_t):\n",
        "    mean = torch.tensor(imagenet_mean)[:,None,None].to(img_t.device)\n",
        "    std  = torch.tensor(imagenet_std)[:,None,None].to(img_t.device)\n",
        "    return (img_t*std + mean).clamp(0,1)\n",
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, backbone, target_layer):\n",
        "        self.backbone = backbone.eval()   # renamed from \"model\"\n",
        "        self.target_layer = target_layer\n",
        "        self.activations = None\n",
        "        self.gradients = None\n",
        "\n",
        "        def fwd_hook(module, inp, out):\n",
        "            self.activations = out.detach()\n",
        "\n",
        "        def bwd_hook(module, grad_in, grad_out):\n",
        "            self.gradients = grad_out[0].detach()\n",
        "\n",
        "        self.fwd_handle = target_layer.register_forward_hook(fwd_hook)\n",
        "        self.bwd_handle = target_layer.register_full_backward_hook(bwd_hook)\n",
        "\n",
        "    def __del__(self):\n",
        "        self.fwd_handle.remove()\n",
        "        self.bwd_handle.remove()\n",
        "\n",
        "    def __call__(self, x, class_idx=None):\n",
        "        x = x.requires_grad_(True)\n",
        "        scores = self.backbone(x)  # renamed from \"self.model\"\n",
        "        if class_idx is None:\n",
        "            class_idx = scores.argmax(1)\n",
        "        sel = scores.gather(1, class_idx.view(-1,1)).squeeze()\n",
        "\n",
        "        self.backbone.zero_grad()\n",
        "        sel.backward(torch.ones_like(sel))\n",
        "\n",
        "        # activations: [B, K, H, W], gradients: [B, K, H, W]\n",
        "        weights = self.gradients.mean(dim=(2,3), keepdim=True)  # [B, K, 1, 1]\n",
        "        cam = (weights * self.activations).sum(dim=1, keepdim=True)  # [B,1,H,W]\n",
        "        cam = torch.relu(cam)\n",
        "\n",
        "        # normalize 0..1 per-sample\n",
        "        B = cam.size(0)\n",
        "        cam_flat = cam.view(B, -1)\n",
        "        cam = (cam - cam_flat.min(dim=1, keepdim=True)[0].view(B,1,1,1)) / \\\n",
        "              (cam_flat.max(dim=1, keepdim=True)[0].view(B,1,1,1) - cam_flat.min(dim=1, keepdim=True)[0].view(B,1,1,1) + 1e-8)\n",
        "        return cam, scores\n",
        "\n",
        "# Attach Grad-CAM to reloaded resnet (kept as \"model\")\n",
        "target_layer = model.layer4\n",
        "gradcam_wrapper = GradCAM(model, target_layer)\n"
      ],
      "metadata": {
        "id": "GjxyNShwekdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_gradcam_samples(n=6):\n",
        "    model.eval()\n",
        "    imgs, labels, names = next(iter(test_loader))\n",
        "    imgs, labels = imgs.to(\"cuda\"), labels.to(\"cuda\")   # move to GPU\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(imgs).argmax(1)\n",
        "\n",
        "    # run grad-cam with the wrapper\n",
        "    cams, _ = gradcam_wrapper(imgs, None)\n",
        "    cams = torch.nn.functional.interpolate(\n",
        "        cams, size=imgs.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "    )\n",
        "\n",
        "    n = min(n, imgs.size(0))\n",
        "    plt.figure(figsize=(12, n*3))\n",
        "    for i in range(n):\n",
        "        img = denorm(imgs[i]).permute(1,2,0).detach().cpu().numpy()   # back to CPU\n",
        "        cam = cams[i,0].detach().cpu().numpy()\n",
        "        overlay = (0.6*img + 0.4*plt.cm.jet(cam)[...,:3])\n",
        "\n",
        "        true_label = names[i]  # assuming names[i] is true label\n",
        "        pred_label = str(preds[i].item())\n",
        "\n",
        "        plt.subplot(n,3,i*3+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
        "\n",
        "        plt.subplot(n,3,i*3+2)\n",
        "        plt.imshow(cam, cmap='jet')\n",
        "        plt.axis('off')\n",
        "        plt.title(\"CAM\")\n",
        "\n",
        "        plt.subplot(n,3,i*3+3)\n",
        "        plt.imshow(overlay)\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Overlay\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "sREkwtg6gXE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_gradcam_samples(6)"
      ],
      "metadata": {
        "id": "rv_m3ZAMgcmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc, RocCurveDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import os\n",
        "\n",
        "# ---------- Helpers to get probabilities and labels ----------\n",
        "@torch.no_grad()\n",
        "def get_probs_and_labels(model, loader, device):\n",
        "    \"\"\"Return (probs, labels, filenames) for entire loader.\n",
        "       probs: np.array shape (N, n_classes)\n",
        "       labels: np.array shape (N,)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    all_names = []\n",
        "    for imgs, labels, names in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        out = model(imgs)                          # logits\n",
        "        probs = F.softmax(out, dim=1).cpu().numpy()  # probabilities\n",
        "        all_probs.append(probs)\n",
        "        all_labels.append(labels.numpy())\n",
        "        all_names.extend(names)\n",
        "    all_probs = np.vstack(all_probs)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    return all_probs, all_labels, all_names\n",
        "\n",
        "# ---------- ROC plotting for multiclass ----------\n",
        "def plot_multiclass_roc(y_true, y_score, n_classes=4, class_names=None, figsize=(8,6)):\n",
        "    \"\"\"\n",
        "    y_true: array shape (N,) with integer labels in 0..n_classes-1\n",
        "    y_score: array shape (N, n_classes) with probabilities for each class\n",
        "    \"\"\"\n",
        "    # Binarize the true labels\n",
        "    y_test_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
        "    if class_names is None:\n",
        "        class_names = [str(i) for i in range(n_classes)]\n",
        "\n",
        "    # Compute per-class ROC and AUC\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC and AUC\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    # Compute macro-average ROC and AUC\n",
        "    # Aggregate all fpr points for interpolation\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "    mean_tpr /= n_classes\n",
        "    fpr[\"macro\"] = all_fpr\n",
        "    tpr[\"macro\"] = mean_tpr\n",
        "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "             label=f'micro-average (AUC = {roc_auc[\"micro\"]:.3f})', linestyle=':', linewidth=2)\n",
        "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "             label=f'macro-average (AUC = {roc_auc[\"macro\"]:.3f})', linestyle='-.', linewidth=2)\n",
        "\n",
        "    colors = plt.cm.get_cmap('tab10', n_classes)\n",
        "    for i, cname in enumerate(class_names):\n",
        "        plt.plot(fpr[i], tpr[i], label=f'{cname} (AUC = {roc_auc[i]:.3f})', linewidth=1.8)\n",
        "\n",
        "    plt.plot([0,1], [0,1], 'k--', linewidth=1)\n",
        "    plt.xlim([-0.02, 1.02])\n",
        "    plt.ylim([-0.02, 1.02])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Multiclass ROC')\n",
        "    plt.legend(loc='lower right', fontsize='small')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# ---------- Training loop with best-model saving and ROC plotted at end ----------\n",
        "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion,\n",
        "                       device, epochs=10, save_path=\"/../segmented_trained_weights_best.pth\",\n",
        "                       n_classes=4, class_names=None, scheduler=None, print_freq=1):\n",
        "    best_acc = 0.0\n",
        "    best_model_w = copy.deepcopy(model.state_dict())\n",
        "    history = {\"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[]}\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # ---- train ----\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0\n",
        "        running_total = 0\n",
        "        for imgs, labels, _ in train_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(imgs)\n",
        "            loss = criterion(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "            preds = out.argmax(1)\n",
        "            running_correct += (preds == labels).sum().item()\n",
        "            running_total += labels.size(0)\n",
        "\n",
        "        train_loss = running_loss / running_total\n",
        "        train_acc = running_correct / running_total\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "\n",
        "        # ---- val ----\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_running_correct = 0\n",
        "        val_running_total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels, _ in val_loader:\n",
        "                imgs = imgs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                out = model(imgs)\n",
        "                loss = criterion(out, labels)\n",
        "                val_running_loss += loss.item() * imgs.size(0)\n",
        "                preds = out.argmax(1)\n",
        "                val_running_correct += (preds == labels).sum().item()\n",
        "                val_running_total += labels.size(0)\n",
        "\n",
        "        val_loss = val_running_loss / val_running_total\n",
        "        val_acc = val_running_correct / val_running_total\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        # scheduler step if provided\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "        # save best\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_w = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model_w, save_path)\n",
        "\n",
        "        if epoch % print_freq == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs} | train_loss {train_loss:.4f} acc {train_acc:.3f} | val_loss {val_loss:.4f} acc {val_acc:.3f} | best_val_acc {best_acc:.3f}\")\n",
        "\n",
        "    # load best before producing final metrics/plots\n",
        "    model.load_state_dict(best_model_w)\n",
        "    print(\"Loaded best model with val_acc = {:.4f}\".format(best_acc))\n",
        "\n",
        "    # get probs + labels from validation (or test) loader\n",
        "    probs, labels, names = get_probs_and_labels(model, val_loader, device)\n",
        "\n",
        "    # Plot ROC\n",
        "    if class_names is None:\n",
        "        class_names = [\"A\",\"D\",\"G\",\"N\"][:n_classes]\n",
        "    plot_multiclass_roc(labels, probs, n_classes=n_classes, class_names=class_names)\n",
        "\n",
        "    return model, history, probs, labels, names\n",
        "\n",
        "# ---------- Example usage ----------\n",
        "# (Adjust epochs, save_path as desired)\n",
        "save_path = \"/../segmented_trained_weights_best.pth\"\n",
        "model, history, probs, labels, names = train_and_evaluate(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=test_loader,      # you can pass a validation loader if you have one\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    device=device,\n",
        "    epochs=10,                   # raise if you want more training\n",
        "    save_path=save_path,\n",
        "    n_classes=4,\n",
        "    class_names=[\"A\",\"D\",\"G\",\"N\"],\n",
        "    scheduler=None               # optionally: torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        ")\n",
        "print(\"ROC plotting finished. Best model saved to:\", save_path)\n"
      ],
      "metadata": {
        "id": "6MJhMD5zqQSh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}